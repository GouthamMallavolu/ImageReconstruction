# CAP6415-Project-ImageReconstruction
Input image reconstruction from features (small network)

# Image Reconstruction from Deep CNN Features using a Lightweight Decoder

This project demonstrates how to reconstruct input images from deep CNN feature maps using a small decoder network.  
It also includes a Streamlit-based user interface that allows you to upload or capture an image and view live reconstructions generated by the trained decoder.

---

## Overview

Deep CNNs learn hierarchical feature representations.  
This work explores how much of the original image information can be recovered from those features.

**Objectives**
- Extract intermediate CNN features from a pretrained encoder (VGG16).
- Train a small, efficient decoder to reconstruct images from these features.
- Provide an interactive web UI for real-time testing.

---

## Repository Structure

```text
opencv-project/
│
├── src/
│   ├── dataset.py              # Loads and normalizes CelebA-HQ dataset
│   ├── encoder.py              # Pretrained VGG16 feature extractor
│   ├── decoder.py              # Lightweight CNN decoder
│   ├── extract_features.py     # Extracts and saves features as .npy files
│   ├── train.py                # Trains decoder using saved feature batches
│   └── test_model.py           # Evaluates reconstruction quality
│
├── app/
│   └── ui_app.py          # Streamlit UI for upload + live camera reconstruction
│
├── models/
│   └── decoder_checkpoints/
│       └── decoder_final.h5    # Trained decoder weights
│
├── data/
│   └── features/               # Pre-extracted feature and image batches
│
├── results/                    # Sample reconstructed outputs
│
└── README.md
```

---

## Environment Setup
Step 1: Create and activate an environment
```bash
conda create -n OpenCV python=3.9
conda activate OpenCV
```
Step 2: Install dependencies
```bash
pip install -r requirements.txt
```
or manually:
```bash
pip install tensorflow==2.10.0 protobuf==3.19.6 streamlit==1.18.0 streamlit-webrtc==0.47.1 altair==4.2.2 vega-datasets numpy pillow opencv-python scikit-image matplotlib
```
### Important:
```text
TensorFlow 2.10 requires protobuf<=3.19.x.
Newer versions of protobuf (≥4.x) are incompatible and will raise descriptor-creation errors.
```

---

## Dataset
```text
CelebA-HQ Dataset
30,000 high-resolution face images.
Images resized to 224×224 and normalized to [0, 1].
```
---

## Expected folder structure:

```text
D:/Datasets/CelebA-HQ/
├── train/
│   ├── image_00001.jpg
│   ├── ...
└── val/
    ├── image_15001.jpg
    ├── ...
```
### Training Pipeline
Step 1: Feature Extraction
Extract feature maps from the pretrained encoder and save them to disk.

```bash
python src/extract_features.py
```
### Saved files:

```text
data/features/feat_00000.npy
data/features/img_00000.npy
...
```
Step 2: Train the Decoder
```bash
python src/train.py
```

---

## Output model:

```text
models/decoder_checkpoints/decoder_final.h5
```
Step 3: Evaluate Reconstruction
```bash
python src/test_model.py
```

---

## Streamlit Web UI
Run the Application
```bash
streamlit run app/ui_app.py
```

The app will open at:

```arduino
http://localhost:8501
```
### UI Features
- Upload Mode: Upload a .jpg or .png image and view its reconstruction.
- Live Camera Mode: Capture webcam input and view reconstructed frames in real time.
- Output Intensity Slider: Adjust reconstruction brightness or scaling interactively.

---

## Results
<img width="600" height="300" alt="comparison_2" src="https://github.com/user-attachments/assets/a9336280-dfad-41a6-a64f-382fb78ca631" />
<img width="600" height="300" alt="comparison_4" src="https://github.com/user-attachments/assets/6d7727bf-2cd2-4041-9380-15673028210c" />

---

## Challenges Faced
- Challenge	Cause	Solution
- Protobuf errors	TensorFlow 2.10 incompatible with protobuf ≥4.x	Pin protobuf==3.19.6
- GPU memory limits	GTX 1650 (4 GB)	Reduce batch size; pre-extract and stream features
- Shape mismatch	Encoder/decoder spatial sizes differ	Align with tf.image.resize() in testing
- Blurry reconstructions	MSE-only objective	Accept for small model; consider perceptual loss in future
- Streamlit import error	Missing altair.vegalite.v4	Install altair==4.2.2

---

## Technical Specifications
- Component	Description
- Encoder	VGG16 pretrained on ImageNet (block3_conv3 output)
- Decoder	Conv2DTranspose + BatchNorm + ReLU (lightweight)
- Feature Input	(32 × 32 × 256)
- Image Output	(224 × 224 × 3)
- Loss	Mean Squared Error (MSE)
- Optimizer	Adam, learning rate = 1e-4
- Hardware	NVIDIA GTX 1650 (4 GB), 16 GB RAM
- Framework	TensorFlow 2.10 / Keras + Streamlit UI

---

## Future Enhancements
- Add perceptual loss (VGG-based) for sharper details.
- Introduce skip connections (U-Net style) to preserve spatial fidelity.
- Compute and display SSIM/PSNR inside the Streamlit UI.
- Add a “download reconstructed image” button in the UI.
- Optional deployment via Streamlit Cloud or Hugging Face Spaces.

---

## Requirements
```text
tensorflow==2.10.0
protobuf==3.19.6
streamlit==1.18.0
streamlit-webrtc==0.47.1
altair==4.2.2
vega-datasets
numpy
pillow
opencv-python
scikit-image
matplotlib
```

---

## Quick Start Guide
```bash
# 1) Extract CNN features
python src/extract_features.py

# 2) Train the lightweight decoder
python src/train.py

# 3) Evaluate image reconstruction
python src/test_model.py

# 4) Launch the Streamlit interface
streamlit run app/ui_app.py
```

Once the Streamlit server starts:

```arduino
http://localhost:8501
```
